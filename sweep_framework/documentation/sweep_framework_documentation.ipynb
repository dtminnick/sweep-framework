{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94ef9f9",
   "metadata": {},
   "source": [
    "# Sweep Framework Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6b36b",
   "metadata": {},
   "source": [
    "This notebook documents the components of a modular sweep framework for text classification.\n",
    "\n",
    "We'll explore each module, configuration, dataset, metrics, loss, training, sweeps, and reporting, and show how they work together.\n",
    "\n",
    "The goal: make experimentation reproducible, extensible, and easy to analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5ed93",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b47149",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e59eaa",
   "metadata": {},
   "source": [
    "Defines the configuration object for a model run.  Stores hyperparameters and provides builder methods for the model, optimizer, and scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4d750",
   "metadata": {},
   "source": [
    "### Class: `ModelConfig`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7d86d",
   "metadata": {},
   "source": [
    "#### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7ed29",
   "metadata": {},
   "source": [
    "`run_type: str` \n",
    "\n",
    "Specifies the type of recurrent model to build.\n",
    "\n",
    "* `LSTM` is a Long Short-Term Memory network, good for handling long-range dependencies.\n",
    "* `GRU` is a Gated Recurrent Unit, simpler and faster, but often comparable in performance to an LSTM.\n",
    "\n",
    "`num_layers: int`\n",
    "\n",
    "The number of stacked recurrent layers.\n",
    "\n",
    "* `1` generates a single-layer RNN.\n",
    "* `>1` generates a deeper RNN, potentially capturing more complex patterns but increasing training time.\n",
    "\n",
    "`hidden_dim: int` \n",
    "\n",
    "Dimensionality of the hidden state of the RNN.\n",
    "\n",
    "* Larger values create more capacity, but at higher risk of overfitting and slower training.\n",
    "* Typical range: 64-512.\n",
    "\n",
    "`bidirectional: bool` \n",
    "\n",
    "Identifies whether to use a bidirectional RNN.\n",
    "\n",
    "* `True` processes sequences forward and backward, useful for tasks where context on both side matters, e.g. sentiment analysis.\n",
    "* `False` standard forward-only RNN.\n",
    "\n",
    "`dropout: float` \n",
    "\n",
    "Sets the dropout probability applied between layers of the RNN.\n",
    "\n",
    "* Range: `0.0-1.0`\n",
    "* Example: `0.3` means 30% of units are randomly dropped during training to reduce overfitting.\n",
    "\n",
    "`embedding_dim: int` \n",
    "\n",
    "Sets the size of word embeddings.\n",
    "\n",
    "* Determines how each token is represented numerically.\n",
    "* Typical values: 50, 100, 300 (GloVe) or 768 (BERT).\n",
    "\n",
    "`vocab_size: int` \n",
    "\n",
    "Number of unique tokens in the volcabulary (must be set before building a model).\n",
    "\n",
    "* Must match the tokenizer's vocabulary size.\n",
    "* Used to initialize the embedding layer.\n",
    "\n",
    "`num_classes: int` \n",
    "\n",
    "Specifies the number of output classes.\n",
    "\n",
    "* For SST-2: `2` (negative, positive)\n",
    "* For SST-5: `5` (very negative, negative, neutral, positive, very positive)\n",
    "\n",
    "`learning_rate: float` \n",
    "\n",
    "Step size for optimizer updates.\n",
    "\n",
    "* Typical values: `1e-3` (Adam), `1e-2` (SGD).\n",
    "* Too high leads to unstable training; too low leads to slow convergence.\n",
    "\n",
    "`optimizer_type: str` \n",
    "\n",
    "Specifies the optimizer type (`Adam`, `SGD`, `AdamW`)\n",
    "\n",
    "* `Adam` provides adaptive learning rates, good default.\n",
    "* `SGD` is stochastic gradient descent, requires tuning.\n",
    "* `AdamW` is `Adam` with weight decay; often better for transfomers.\n",
    "\n",
    "`num_epochs: int`\n",
    "\n",
    "Maximum number of training epochs.\n",
    "\n",
    "* Each epoch equals one full pass through the training set.\n",
    "* Early stopping may halt training before this.\n",
    "\n",
    "`patience: int` \n",
    "\n",
    "Number of epochs to wait for improvement before early stopping.\n",
    "\n",
    "* Example: `patience = 2` will trigger stop if validation metric doesn't improve for 2 consecutive epochs.\n",
    "\n",
    "`run_group: str` \n",
    "\n",
    "Optional label for grouping runs in sweeps.\n",
    "\n",
    "* Useful for organizing experiments, e.g. `lstm_baseline` versus `gru_baseline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d23cc",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff2d5d",
   "metadata": {},
   "source": [
    "#### `build_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156b2fc",
   "metadata": {},
   "source": [
    "Returns a PyTorch model configured with embeddings, RNN, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf377fc",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34c00e",
   "metadata": {},
   "source": [
    "None (uses attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afeea4c",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8a634",
   "metadata": {},
   "source": [
    "PyTorch model (`nn.Module`) configured with embeddings, RNN, and classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c80789",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6164110",
   "metadata": {},
   "source": [
    "Requires `vocab_size` and `num_classes` to be set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85cdc7",
   "metadata": {},
   "source": [
    "#### `build_optimizer(parameters)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d25d03",
   "metadata": {},
   "source": [
    "Returns optimizer instance bound to model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb36c1",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3563f",
   "metadata": {},
   "source": [
    "`parameters`: iterable of model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e96f7ac",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f470183",
   "metadata": {},
   "source": [
    "Optimizer instance (`torch.optim.Adam`, `SGD`, `AdamW`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44f360",
   "metadata": {},
   "source": [
    "#### `build_scheduler(optimizer)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0569223",
   "metadata": {},
   "source": [
    "Returns learning rate scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877a20d",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2edb4",
   "metadata": {},
   "source": [
    "`optimizer`: optimizer instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2bce51",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c111c",
   "metadata": {},
   "source": [
    "Learning rate scheduler (`torch.optim.lr_scheduler.StepLR`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83947cc6",
   "metadata": {},
   "source": [
    "#### `to_dict`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c376dd9",
   "metadata": {},
   "source": [
    "Returns a dictionary of all configuration attributes for logging and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a142d",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab4ebd",
   "metadata": {},
   "source": [
    "None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43610f31",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3080868",
   "metadata": {},
   "source": [
    "Dictionary of all configuration attributes for logging and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d741a",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2c5d0",
   "metadata": {},
   "source": [
    "We define a configuration for an LSTM model with 2 layers, hidden size 128, dropout 0.3, and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b09092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sweep_framework.config.model_config import ModelConfig\n",
    "\n",
    "config = ModelConfig(\n",
    "    run_type=\"LSTM\",\n",
    "    num_layers=2,\n",
    "    hidden_dim=128,\n",
    "    bidirectional=True,\n",
    "    dropout=0.3,\n",
    "    embedding_dim=100,\n",
    "    vocab_size=30522,   # from tokenizer\n",
    "    num_classes=2,      # SST-2 is binary\n",
    "    learning_rate=1e-3,\n",
    "    optimizer_type=\"Adam\",\n",
    "    num_epochs=3,\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "print(config.to_dict())\n",
    "\n",
    "# Build model, optimizer, scheduler\n",
    "model = config.build_model()\n",
    "optimizer = config.build_optimizer(model.parameters())\n",
    "scheduler = config.build_scheduler(optimizer)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eb5e8f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fca6e2",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde74111",
   "metadata": {},
   "source": [
    "The `Dataset` class manages raw examples, stratified splits, and PyTorch DataLoaders.  It acts as the bridge between HuggingFace datasets (or any `(text, label)` pairs) and the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0793612",
   "metadata": {},
   "source": [
    "#### Class: `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8fc77",
   "metadata": {},
   "source": [
    "#### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fb18e",
   "metadata": {},
   "source": [
    "`examples: List[Tuple[str, int]]`\n",
    "\n",
    "Raw dataset examples as `(text, label)` pairs.  Labels must be integers in `[0, num_classes - 1]`.\n",
    "\n",
    "Note: filter out invalid labels, e.g. `-1` in the SST-2 test set.\n",
    "\n",
    "`train_examples: List[Tuple[str, int]]`\n",
    "\n",
    "Subset of examples used for training.\n",
    "\n",
    "`val_examples: List[Tuple[str, int]]`\n",
    "\n",
    "Subset of examples used for validation.\n",
    "\n",
    "`test_examples: List[Tuple[str, int]]`\n",
    "\n",
    "Subset of examples used for testing.\n",
    "\n",
    "`train_loader: DataLoader`\n",
    "\n",
    "PyTorch DataLoader for training set.\n",
    "\n",
    "`val_loader: DataLoader`\n",
    "\n",
    "PyTorch DataLoader for validation set.\n",
    "\n",
    "`test_loader: DataLoader`\n",
    "\n",
    "PyTorch DataLoader for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662378fe",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d8130",
   "metadata": {},
   "source": [
    "`__init__(self, examples: List[Tuple[str, int]])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9628a",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7ea48",
   "metadata": {},
   "source": [
    "`examples`: List of `(text, label)` pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535a24c",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eca73f",
   "metadata": {},
   "source": [
    "Initializes dataset with raw examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67dfdfa",
   "metadata": {},
   "source": [
    "#### `stratify_split(self, train_ratio = 0.8, val_ratio = 0.1, test_ratio = 0.1, seed = 42)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef34f9",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed04d4",
   "metadata": {},
   "source": [
    "`train_ratio`: Proportion of examples for training.\n",
    "\n",
    "`val_ratio`: Proportion for validation.\n",
    "\n",
    "`test_ratio`: Proportion for testing.\n",
    "\n",
    "`seed`: Random seed for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
